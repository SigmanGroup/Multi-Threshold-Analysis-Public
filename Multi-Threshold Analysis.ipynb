{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863b013a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af081774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:25.616028Z",
     "start_time": "2023-09-28T18:07:23.704214Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import hotspot_utils\n",
    "from hotspot_classes import Threshold, Hotspot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "NUM_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cefa64",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38059b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:29.051824Z",
     "start_time": "2023-09-28T18:07:25.905944Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell reads in parameters and response data from Excel files and combines them into a single dataframe\n",
    "# Check cell outputs to make sure everything looks good\n",
    "\n",
    "parameters_file = \"Multi-Threshold Analysis Data\" # Excel file to pull parameters from\n",
    "parameters_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull parameters from\n",
    "parameters_start_col = 3   # 0-indexed column number where the parameters start\n",
    "parameters_num_parameters = 190 # Number of parameters in the parameters file\n",
    "parameters_num_responses = 450 # Number of responses/ligands in the parameters file\n",
    "parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "response_file = \"Multi-Threshold Analysis Data\" # Excel file to pull responses from\n",
    "response_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull responses from\n",
    "response_num_samples = 450 # Number of samples/reactions in the response file\n",
    "response_col = 1 # 0-indexed column number for the responses\n",
    "response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "response_header_rows = 1 # Number of rows to skip when reading the responses\n",
    "\n",
    "# If the parameters and outputs are on different sheets, you can use the following code to read them in separately\n",
    "\n",
    "# parameters_file = \"kraken descriptors\" # Excel file to pull parameters from\n",
    "# parameters_sheet = \"DFT_data\" # Sheet in the Excel file to pull parameters from\n",
    "# parameters_start_col = 1   # 0-indexed column number where the parameters start\n",
    "# parameters_num_parameters = 190 # Number of parameters in the parameters file\n",
    "# parameters_num_responses = 1560 # Number of responses/ligands in the parameters file\n",
    "# parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "# response_file = \"Multi-Threshold Analysis Data\" # Excel file to pull responses from\n",
    "# response_sheet = \"Reactions VI-IX\" # Sheet in the Excel file to pull responses from\n",
    "# response_num_samples = 100 # Number of samples/reactions in the response file\n",
    "# response_col = 2 # 0-indexed column number for the responses\n",
    "# response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# response_header_rows = 0 # Number of rows to skip when reading the responses\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# EDIT ABOVE THIS LINE\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Actually start reading stuff into dataframes\n",
    "parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_responses + 1,\n",
    "                              usecols = list(range(0, (parameters_num_parameters + parameters_start_col)))\n",
    "                              )\n",
    "response_df = pd.read_excel(\"./InputData/\" + response_file + \".xlsx\",\n",
    "                            response_sheet,\n",
    "                            header = response_header_rows,\n",
    "                            index_col = response_y_label_col,\n",
    "                            nrows = response_num_samples,\n",
    "                            usecols = list(range(0, response_col + 1))\n",
    "                            )\n",
    "\n",
    "\n",
    "# Drop any columns before parameters_start_col that are not the index column\n",
    "parameters_columns_to_keep = [col for col in range(0, len(parameters_df.columns)) if col >= parameters_start_col-1]\n",
    "parameters_df = parameters_df.iloc[:,parameters_columns_to_keep]\n",
    "\n",
    "# Combine the two dataframes into the master dataframe\n",
    "response_df.drop(response_df.columns[0:response_col-1], axis = 'columns', inplace = True)\n",
    "response_df['y_class'] = 0 # This should create the \"y_class\" column that will ultimately be used for classification labels\n",
    "data_df = response_df.merge(parameters_df, left_index = True, right_index = True)\n",
    "data_df.columns.values[0] = 'response' # Converts the output column name from whatever it is on the spreadsheet\n",
    "data_df.dropna(inplace = True) # This covers the entire masking section and trims the dataframe down to only the rows relevant to this dataset\n",
    "\n",
    "# This converts all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "for column in data_df.columns:\n",
    "    data_df[column] = pd.to_numeric(data_df[column], errors='coerce')\n",
    "data_df.dropna(inplace = True)\n",
    "\n",
    "# Creates a dictionary to convert x# labels to full parameter names\n",
    "x_names = list(parameters_df.iloc[0, :parameters_num_parameters])\n",
    "x_labels = list(parameters_df.columns)[:parameters_num_parameters]\n",
    "x_labelname_dict = dict(zip(x_labels, x_names))\n",
    "\n",
    "# Print out some information about the dataframe to confirm it was read in correctly\n",
    "print(\"Parameter file shape: {}\".format(parameters_df.shape))\n",
    "print(\"Final parameter quantity: {}\".format(len(x_labels)))\n",
    "print(\"Final experiment quantity: {}\".format(data_df.shape[0]))\n",
    "print(\"First parameter cell: {}\".format(data_df[x_labels[0]].iloc[0]))\n",
    "print(\"Last parameter cell:  {}\".format(data_df[x_labels[-1]].iloc[-1]))\n",
    "print(\"First response: {}\".format(data_df.iloc[0,0]))\n",
    "print(\"Last response:  {}\".format(data_df.iloc[-1,0]))\n",
    "print(\"First reaction label: {}\".format(data_df.index[0]))\n",
    "print(\"Last reaction label:  {}\".format(data_df.index[-1]))\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb07018",
   "metadata": {},
   "source": [
    "# Training/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cb079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:42.192285Z",
     "start_time": "2023-09-28T18:07:42.102266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Divide the data into training and test sets\n",
    "# split options are 'random', 'ks' (kennard-stone), 'y_equidist' (equidistant in y), 'define' (manual selection) and 'none'\n",
    "split = \"none\"\n",
    "test_ratio = 0.3 \n",
    "\n",
    "training_set, test_set = hotspot_utils.train_test_splits(data_df, split, test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b3fc6",
   "metadata": {},
   "source": [
    "# Run the Combined Threshold Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bd2e9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Automatic Threshold Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe3f47",
   "metadata": {},
   "source": [
    "Edit and run the first cell to set the parameters of the threshold analysis, then run the second cell without changing anything (unless you have a good reason to) to start the calculations.\n",
    "\n",
    "This section automatically identifies the best hotspots/multi-thresholds based on the parameters set in the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7cb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:29.320787Z",
     "start_time": "2023-09-28T18:07:29.306785Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cutoff in your output for what counts as an active ligand\n",
    "y_cut = 10\n",
    "\n",
    "# Set to True if you want points below the y-cut to be considered active\n",
    "low_is_good = False\n",
    "\n",
    "# How heavily to value active ligands (1) over inactive ligands (0)\n",
    "class_weight = {1:10, 0:1} \n",
    "\n",
    "# How the prune_hotspots and find_best_hotspots evaluates which are the best\n",
    "# Can be set to 'accuracy', 'weighted_accuracy', 'f1', and 'weighted_f1'\n",
    "evaluation_method = 'weighted_accuracy'\n",
    "\n",
    "# How many threshold dimensions do you want?\n",
    "n_thresholds = 2\n",
    "\n",
    "# What percentage of thresholds are analyzed in each subsequent step\n",
    "percentage = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up y_class, the binary list of which y values are above y_cut\n",
    "if(low_is_good):\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] < y_cut)\n",
    "else:\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] > y_cut)\n",
    "\n",
    "# Find the best thresholds within the full X and y space and make single threshold hotspot objects from them\n",
    "all_thresholds = hotspot_utils.threshold_generation(data_df, class_weight, evaluation_method, x_labelname_dict)\n",
    "best_hotspots = []\n",
    "for thresh in all_thresholds:\n",
    "    temp_hs = Hotspot(data_df, [thresh], y_cut, training_set, test_set, evaluation_method, class_weight)\n",
    "    best_hotspots.append(temp_hs)\n",
    "\n",
    "# Cut down to the best {percentage} hotspots\n",
    "best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "\n",
    "# Add more thresholds, pruning after each step for resource management\n",
    "for i in range(n_thresholds - 1):\n",
    "    with Pool(processes=int(NUM_CORES*.7)) as p:\n",
    "        new_hotspots = p.starmap(hotspot_utils.hs_next_thresholds_fast, zip(best_hotspots, repeat(all_thresholds)))\n",
    "    new_hotspots = [item for sublist in new_hotspots for item in sublist] \n",
    "    \n",
    "    best_hotspots = hotspot_utils.prune_hotspots(new_hotspots, percentage, evaluation_method)\n",
    "\n",
    "best_hotspots.sort(key = lambda x: x.accuracy_dict[evaluation_method], reverse = True)\n",
    "\n",
    "# print the top 5 hotspots\n",
    "for i, hs in enumerate(best_hotspots[:5]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50faa826",
   "metadata": {},
   "source": [
    "## Manual Threshold Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a86187",
   "metadata": {},
   "source": [
    "Edit and run the first cell to set the parameters of the threshold analysis, then run the second cell without changing anything (unless you have a good reason to) to start the calculations.\n",
    "\n",
    "This section allows you to manually select which feature(s) or range of features are used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b52da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:11:27.829533Z",
     "start_time": "2023-09-28T18:11:27.817523Z"
    }
   },
   "outputs": [],
   "source": [
    "# What features do you want in your hotspot?\n",
    "# For ranges, use data_df.columns[x:y].to_list() to get a list of feature xIDs\n",
    "# For specific features, use ['xID1', 'xID2', ...]\n",
    "\n",
    "manual_features = [['x1'], ['x87']]\n",
    "# manual_features = [['x87']]\n",
    "# manual_features = [['x1'], ['x87'], data_df.columns[3:].to_list()]\n",
    "\n",
    "# Cutoff for what counts as a hit\n",
    "y_cut = 10\n",
    "\n",
    "# How heavily to value hits (1) over misses (0)\n",
    "class_weight = {1:10, 0:1} \n",
    "\n",
    "# What percentage of hotspots to take through to each subsequent step\n",
    "# Only relevant if using ranges instead of specific parameters\n",
    "percentage = 100\n",
    "\n",
    "# How the prune_hotspots and find_best_hotspots evaluates which are the best\n",
    "# Can be set to 'accuracy', 'weighted_accuracy', 'f1', and 'weighted_f1'\n",
    "evaluation_method = 'weighted_accuracy'\n",
    "\n",
    "# Set to True if you want a hotspot of low output results (cold spot?)\n",
    "low_is_good = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110d9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:11:28.932105Z",
     "start_time": "2023-09-28T18:11:28.819069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up y_class, the binary list of which y values are above y_cut\n",
    "if(low_is_good):\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] < y_cut)\n",
    "else:\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] > y_cut)\n",
    "\n",
    "# Find the best thresholds within the full X and y space and make single threshold hotspot objects from them\n",
    "all_thresholds = hotspot_utils.threshold_generation(data_df, class_weight, evaluation_method, x_labelname_dict, manual_features[0])\n",
    "best_hotspots = []\n",
    "for thresh in all_thresholds:\n",
    "    temp_hs = Hotspot(data_df, [thresh], y_cut, training_set, test_set, evaluation_method, class_weight)\n",
    "    best_hotspots.append(temp_hs)\n",
    "\n",
    "# Cut down to the best {percentage} hotspots\n",
    "best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "\n",
    "# Add more thresholds, pruning after each step for resource management\n",
    "for i in range(len(manual_features) - 1):\n",
    "    new_hotspots = []\n",
    "    for hs in best_hotspots:\n",
    "        temp_hotspots = hotspot_utils.hs_next_thresholds(hs, data_df, class_weight, x_labelname_dict, manual_features[i+1])\n",
    "        new_hotspots.extend(temp_hotspots)\n",
    "    best_hotspots = new_hotspots\n",
    "    del (new_hotspots)\n",
    "    best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "    \n",
    "best_hotspots.sort(key = lambda x: x.accuracy_dict[evaluation_method], reverse = True)\n",
    "\n",
    "# print the top 5 hotspots\n",
    "for i, hs in enumerate(best_hotspots[:5]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bfbd7",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f1a2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Print Longer List of Hotspots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28e8d2",
   "metadata": {},
   "source": [
    "This cell prints the text output for a longer list of hotspots if you want to see more than were given in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178fdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T19:04:05.022913Z",
     "start_time": "2023-01-30T19:04:05.014923Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How many hotspots do you want listed?\n",
    "n = 50\n",
    "\n",
    "for i, hs in enumerate(best_hotspots[:n]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff653",
   "metadata": {},
   "source": [
    "## Display Individual Hotspot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ac378",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066012c",
   "metadata": {},
   "source": [
    "Run these functions before running the Display Plots section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a63be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:09:14.621512Z",
     "start_time": "2023-09-28T18:09:14.588496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is a set of functions for plotting multi-threshold hotspots. They've been included in the main script for ease of modification if you want to change how the plots look.\n",
    "\n",
    "def plot(hs:Hotspot, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = '% Yield'):\n",
    "    \"\"\"\n",
    "    Plot a single, double, or triple threshold by calling the relevant function\n",
    "\n",
    "    :hs: Hotspot object to plot\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default '% Yield'\n",
    "    \"\"\"\n",
    "    if(len(hs.thresholds)==1):\n",
    "        plot_single_threshold(hs, subset, coloring, gradient_color, output_label)\n",
    "    elif(len(hs.thresholds)==2):\n",
    "        plot_double_threshold(hs, subset, coloring, gradient_color, output_label)\n",
    "    elif(len(hs.thresholds)==3):\n",
    "        plot_triple_threshold(hs, subset, coloring, gradient_color, output_label)\n",
    "    else:\n",
    "        print(f'Unable to plot {len(hs.thresholds)} thresholds')\n",
    "\n",
    "def plot_single_threshold(hs:Hotspot, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = '% Yield'):\n",
    "    \"\"\"\n",
    "    Plot a single threshold in 2 dimensions\n",
    "\n",
    "    :hs: Hotspot object to plot\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default '% Yield'\n",
    "    \"\"\"\n",
    "\n",
    "    x_col = hs.thresholds[0].index\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # This section auto-scales the plot\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, 'response']))\n",
    "    y_max = float(max(hs.data_df.loc[:, 'response']))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    \n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "    \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "\n",
    "    # This is where it selects which descriptors to plot\n",
    "    x = hs.data_df.loc[points_to_plot, x_col]\n",
    "    y = hs.data_df.loc[points_to_plot, 'response']\n",
    "    plt.scatter(x, y, c = mapping_cl, cmap = gradient_color, edgecolor ='black', s = 100)\n",
    "    \n",
    "    # Set the gradient bar or binary legend\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[0], shrink=1)\n",
    "        cbar.set_label(output_label, rotation=90, size=25)     \n",
    "        cbar.ax.tick_params(labelsize=18)   \n",
    "    elif(coloring == 'binary'):\n",
    "        colormap = plt.get_cmap(gradient_color)\n",
    "        active_color = mcolors.to_hex(colormap(1.0))\n",
    "        inactive_color = mcolors.to_hex(colormap(0.0))\n",
    "        active_patch = mpatches.Patch(color=active_color, label='Active ligands', edgecolor='black')\n",
    "        inactive_patch = mpatches.Patch(color=inactive_color, label='Inactive ligands', edgecolor='black')\n",
    "        plt.legend(handles=[active_patch, inactive_patch], fontsize=15, loc='upper right', edgecolor='black')\n",
    " \n",
    "    \n",
    "    # Draw the threshold line\n",
    "    plt.axvline(x=hs.thresholds[0].cut_value, color='black', linestyle='--')\n",
    "    # Draw y_cut line\n",
    "    plt.axhline(y=hs.y_cut, color='r', linestyle='--')\n",
    "\n",
    "    # Axis setup\n",
    "    plt.xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}',fontsize=25)\n",
    "    plt.ylabel(output_label,fontsize=25)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.locator_params(axis='x', nbins=5)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "\n",
    "    plt.title(f'{hs.thresholds[0].feature_name} Threshold', fontsize = 25)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_double_threshold(hs:Hotspot, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = 'Yield (%)'):\n",
    "    \"\"\"\n",
    "    Plot a double threshold in 2 dimensions\n",
    "\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default 'Yield (%)'\n",
    "    \"\"\"\n",
    "\n",
    "    x_col,y_col = hs.thresholds[0].index, hs.thresholds[1].index\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # This section auto-scales the plot\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, y_col]))\n",
    "    y_max = float(max(hs.data_df.loc[:, y_col]))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    \n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "    \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "\n",
    "    # This is where it selects which descriptors to plot\n",
    "    x = hs.data_df.loc[points_to_plot,x_col]\n",
    "    y = hs.data_df.loc[points_to_plot,y_col]\n",
    "    plt.scatter(x, y, c=mapping_cl,cmap=gradient_color, edgecolor='black', s=100)  \n",
    "\n",
    "    # Draw threshold lines\n",
    "    plt.axhline(y=hs.thresholds[1].cut_value, color='black', linestyle='--')\n",
    "    plt.axvline(x=hs.thresholds[0].cut_value, color='black', linestyle='--')\n",
    "    \n",
    "    # Set the gradient bar or binary legend\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[0], shrink=1)\n",
    "        cbar.set_label(output_label, rotation=90, size=18)\n",
    "    elif(coloring == 'binary'):\n",
    "        colormap = plt.get_cmap(gradient_color)\n",
    "        active_color = mcolors.to_hex(colormap(1.0))\n",
    "        inactive_color = mcolors.to_hex(colormap(0.0))\n",
    "        active_patch = mpatches.Patch(color=active_color, label='Active ligands', edgecolor='black')\n",
    "        inactive_patch = mpatches.Patch(color=inactive_color, label='Inactive ligands', edgecolor='black')\n",
    "        plt.legend(handles=[active_patch, inactive_patch], fontsize=15, loc='upper right', edgecolor='black')\n",
    "\n",
    "    # Axis setup\n",
    "    plt.xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}', fontsize = 15)\n",
    "    plt.ylabel(f'{hs.thresholds[1].feature_label} {hs.thresholds[1].feature_name}', fontsize = 15)\n",
    "    plt.xticks(fontsize = 18)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.yticks(fontsize = 18)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.locator_params(axis = 'y', nbins = 4)\n",
    "\n",
    "    # Print the title of the plot\n",
    "    plt.title(f'{hs.thresholds[0].feature_name} x {hs.thresholds[1].feature_name}', fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_triple_threshold(hs:Hotspot, subset:str ='all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = '% Yield'):\n",
    "    \"\"\"\n",
    "    Plot a triple threshold in 3 dimensions\n",
    "\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default '% Yield'\n",
    "    \"\"\"\n",
    "\n",
    "    x_col,y_col,z_col = hs.thresholds[0].index, hs.thresholds[1].index, hs.thresholds[2].index\n",
    "    \n",
    "    # Auto-scale the plot to your data\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, y_col]))\n",
    "    y_max = float(max(hs.data_df.loc[:, y_col]))\n",
    "    z_min = float(min(hs.data_df.loc[:, z_col]))\n",
    "    z_max = float(max(hs.data_df.loc[:, z_col]))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "    dz = abs(z_min - z_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    z_min = z_min - abs(dz * 0.05)\n",
    "    z_max = z_max + abs(dz * 0.05)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "        \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "\n",
    "    # Actually plot the data\n",
    "    x = hs.data_df.loc[points_to_plot,x_col]\n",
    "    y = hs.data_df.loc[points_to_plot,y_col]\n",
    "    z = hs.data_df.loc[points_to_plot,z_col]\n",
    "    ax.scatter(x, y, z, c=mapping_cl, cmap=gradient_color, alpha=0.95, marker=\"s\", s=50, edgecolors='k') \n",
    "        \n",
    "    # Plot the z-axis threshold\n",
    "    temp_x = np.linspace(x_min, x_max, num=10)\n",
    "    temp_y = np.linspace(y_min, y_max, num=10)\n",
    "    temp_x, temp_y = np.meshgrid(temp_x, temp_y)\n",
    "    temp_z = hs.thresholds[2].cut_value + 0 * temp_x + 0 * temp_y\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray')\n",
    "    \n",
    "    # Plot the x-axis threshold\n",
    "    temp_y = np.linspace(y_min, y_max, num=10)\n",
    "    temp_z = np.linspace(z_min, z_max, num=10)\n",
    "    temp_z, temp_y = np.meshgrid(temp_z, temp_y)\n",
    "    temp_x = hs.thresholds[0].cut_value + 0 * temp_z + 0 * temp_y\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray') \n",
    "    \n",
    "    # Plot the y-axis threshold\n",
    "    temp_x = np.linspace(x_min, x_max, num = 10)\n",
    "    temp_z = np.linspace(z_min, z_max, num = 10)\n",
    "    temp_x, temp_z = np.meshgrid(temp_x, temp_z)\n",
    "    temp_y = hs.thresholds[1].cut_value + 0 * temp_x + 0 * temp_z\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray')\n",
    "    \n",
    "    plt.xticks(fontsize = 10) \n",
    "    plt.yticks(fontsize = 10)\n",
    "\n",
    "    # Set axes labels\n",
    "    ax.set_xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}',fontsize=12.5)\n",
    "    ax.set_ylabel(f'{hs.thresholds[1].feature_label} {hs.thresholds[1].feature_name}',fontsize=12.5)\n",
    "    ax.set_zlabel(f'{hs.thresholds[2].feature_label} {hs.thresholds[2].feature_name}',fontsize=12.5)\n",
    "    plt.locator_params(axis='y', nbins=8)\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_zlim(z_min, z_max)\n",
    "    \n",
    "    # Set the gradient bar on the side\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[0], shrink=0.5)\n",
    "        cbar.set_label(output_label, rotation=90, size=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155f02c",
   "metadata": {},
   "source": [
    "### Display Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fbe91",
   "metadata": {},
   "source": [
    "For more direct control over plot style, changes can be made to functions in the cell above. The above functions must be run before this cell can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef61685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the hotspot you want to plot based on its index\n",
    "hotspot_index = 0\n",
    "print(best_hotspots[hotspot_index])\n",
    "\n",
    "\n",
    "# subset can be 'all', 'training', or 'test'\n",
    "# You can change the coloring to either 'scaled' or 'binary'\n",
    "# output_label is whatever you call your output (Only relevant when using 'scaled' coloring or single threshold)\n",
    "plot(best_hotspots[hotspot_index], subset='all', coloring='binary', output_label='Yield (%)', gradient_color='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc47692",
   "metadata": {},
   "source": [
    "# Virtual Screening / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f864f6",
   "metadata": {},
   "source": [
    "## Import Virtual Screening / Validation Parameter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9264a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the parameters for the previously unseen molecules, required for both virtual screening and validation\n",
    "# This assumes the excel sheet has a row of xID labels then a row of full parameter names\n",
    "parameters_file = \"kraken descriptors\" \n",
    "parameters_sheet = \"DFT_data\" \n",
    "parameters_num_parameters = 190\n",
    "parameters_start_col = 1   # 0-indexed\n",
    "parameters_num_samples = 1560 \n",
    "parameters_y_label_col = 0  # 0-indexed\n",
    "parameters_header_rows = 0\n",
    "\n",
    "\n",
    "# Actually start reading stuff into the parameter dataframe\n",
    "vs_parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_samples + 1,\n",
    "                              usecols = list(range(0, (parameters_num_parameters + parameters_start_col)))\n",
    "                              )\n",
    "\n",
    "# Create a dictionary to convert x# labels to full parameter names\n",
    "vs_x_names = list(vs_parameters_df.iloc[0, parameters_start_col - 1 : parameters_num_parameters + parameters_start_col - 1])\n",
    "vs_x_labels = list(vs_parameters_df.columns)[parameters_start_col - 1 : parameters_num_parameters + parameters_start_col - 1]\n",
    "vs_x_labelname_dict = dict(zip(vs_x_labels, vs_x_names))\n",
    "\n",
    "vs_parameters_df.drop(vs_parameters_df.index[0], inplace=True) # Remove the full parameter name row\n",
    "vs_parameters_df.index = vs_parameters_df.index.astype(int) # This converts the index (molecule/reaction number) from strings to ints\n",
    "\n",
    "# Convert all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "for column in vs_parameters_df.columns:\n",
    "    vs_parameters_df[column] = pd.to_numeric(vs_parameters_df[column], errors='coerce')\n",
    "\n",
    "display(vs_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a18719",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation results from the excel sheet\n",
    "# The final result should be a dataframe with indicies corresponding to the vs_parameters_df from above,\n",
    "# a column of experimental outputs, and all the relevant parameters\n",
    "\n",
    "validation_file = \"Multi-Threshold Analysis Data\"\n",
    "validation_sheet = \"Reaction XII\"\n",
    "validation_experimental_col = 2\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "vs_response_df = pd.read_excel('./InputData/' + validation_file + '.xlsx',\n",
    "                              sheet_name=validation_sheet,\n",
    "                              index_col=0,\n",
    "                              )\n",
    "\n",
    "# Drop all columns except the experimental output\n",
    "vs_response_df = vs_response_df.iloc[:, [validation_experimental_col-1]]\n",
    "vs_response_df.columns = ['response']\n",
    "\n",
    "for column in vs_response_df.columns:\n",
    "    vs_response_df[column] = pd.to_numeric(vs_response_df[column], errors='coerce')\n",
    "vs_response_df.dropna(inplace = True)\n",
    "\n",
    "vs_combined_df = pd.concat([vs_response_df, vs_parameters_df], axis=1, join='inner')\n",
    "\n",
    "display(vs_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d520c9",
   "metadata": {},
   "source": [
    "### Print/Export Validation Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hotspot to validate\n",
    "hotspot_index = 0\n",
    "\n",
    "# Set to True if you want to write the validation results to an Excel file\n",
    "write_to_excel = False\n",
    "output_name = 'validation_output.xlsx'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hs = best_hotspots[hotspot_index]\n",
    "\n",
    "# Begin the output dataframe with the experimental results and the y_class column\n",
    "validation_report_df = vs_response_df.copy()\n",
    "validation_report_df['y_class'] = [y > hs.y_cut for y in validation_report_df.iloc[:, 0]]\n",
    "\n",
    "# Add the parameter values and binary evaluations for each ligand to the output dataframe\n",
    "# True in an xID column indicates that the ligand is predicted to be active by that threshold\n",
    "for parameter in hs.threshold_indexes:\n",
    "    validation_report_df[f'{parameter}_{vs_x_labelname_dict[parameter]}'] = vs_parameters_df.loc[validation_report_df.index, parameter]\n",
    "\n",
    "threshold_evaluations = hs.expand(vs_parameters_df.loc[validation_report_df.index])\n",
    "validation_report_df = pd.concat([validation_report_df, threshold_evaluations], axis=1)\n",
    "\n",
    "# Create a column for the final hotspot evaluation if there is more than a single threshold\n",
    "if len(hs.thresholds) > 1:\n",
    "    for ligand in validation_report_df.index:\n",
    "        evaluation = all([validation_report_df.loc[ligand, threshold] for threshold in hs.threshold_indexes])\n",
    "        validation_report_df.loc[ligand, 'Full Hotspot Evaluation'] = evaluation\n",
    "\n",
    "display(validation_report_df)\n",
    "\n",
    "hs.get_external_accuracy(vs_combined_df, verbose=True)\n",
    "\n",
    "if write_to_excel:\n",
    "    validation_report_df.to_excel(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725930a6",
   "metadata": {},
   "source": [
    "### Plot Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b05b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your validation data on the hotspot selected by hotspot_index\n",
    "# Modify the last line for plotting options\n",
    "hotspot_index = 0\n",
    "hs = best_hotspots[hotspot_index]\n",
    "\n",
    "def plot_validation(hs:Hotspot, response_data:pd.DataFrame, vs_parameters:pd.DataFrame, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = 'Yield (%)', hide_og=False):\n",
    "    \"\"\"\n",
    "    Plot a single, double, or triple threshold by calling the relevant function\n",
    "\n",
    "    :hs: The hotspot object to plot\n",
    "    :response_data: The experimental output data for the validation set\n",
    "    :vs_parameters: The parameter data for the validation set\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot if also plotting the original data\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default 'Yield (%)'\n",
    "    :hide_og: True (default) if you want to hide the original data points\n",
    "    \"\"\"\n",
    "    if(len(hs.thresholds)==1):\n",
    "        plot_validation_single_threshold(hs, response_data, vs_parameters, subset, coloring, gradient_color, output_label, hide_og)\n",
    "    elif(len(hs.thresholds)==2):\n",
    "        plot_validation_double_threshold(hs, response_data, vs_parameters, subset, coloring, gradient_color, output_label, hide_og)\n",
    "    elif(len(hs.thresholds)==3):\n",
    "        plot_validation_triple_threshold(hs, response_data, vs_parameters, subset, coloring, gradient_color, output_label, hide_og)\n",
    "    else:\n",
    "        print(f'Unable to plot {len(hs.thresholds)} thresholds')\n",
    "\n",
    "def plot_validation_single_threshold(hs:Hotspot, response_data:pd.DataFrame, vs_parameters:pd.DataFrame, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = 'Yield (%)', hide_og=False):\n",
    "    \"\"\"\n",
    "    Plot a validation set on a single threshold\n",
    "\n",
    "    :hs: The hotspot object to plot\n",
    "    :response_data: The experimental output data for the validation set\n",
    "    :vs_parameters: The parameter data for the validation set\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot if also plotting the original data\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default 'Yield (%)'\n",
    "    :hide_og: True (default) if you want to hide the original data points\n",
    "    \"\"\"\n",
    "\n",
    "    x_col = hs.thresholds[0].index\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # This section auto-scales the plot\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, 'response']))\n",
    "    y_max = float(max(hs.data_df.loc[:, 'response']))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    \n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "    \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "        vs_mapping_cl = response_data.iloc[:, 0]\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "        vs_mapping_cl = [1 if i >= hs.y_cut else 0 for i in response_data.iloc[:, 0]]\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "\n",
    "    # This is where it selects which descriptors to plot\n",
    "    if not hide_og:\n",
    "        x = hs.data_df.loc[points_to_plot, x_col]\n",
    "        y = hs.data_df.loc[points_to_plot, 'response']\n",
    "        plt.scatter(x, y, c = mapping_cl, cmap = gradient_color, edgecolor ='black', s = 100)\n",
    "\n",
    "    # Plot the validation data set on top of the hotspot\n",
    "    vs_x = vs_parameters.loc[response_data.index, x_col]\n",
    "    vs_y = response_data.iloc[:, 0]\n",
    "    plt.scatter(vs_x, vs_y, c = vs_mapping_cl, cmap = gradient_color, edgecolor = 'black', s = 100, marker = 's')\n",
    "    \n",
    "    # Set the gradient bar or binary legend\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[0], shrink=1)\n",
    "        cbar.set_label(output_label, rotation=90, size=25)     \n",
    "        cbar.ax.tick_params(labelsize=18)   \n",
    "    elif(coloring == 'binary'):\n",
    "        colormap = plt.get_cmap(gradient_color)\n",
    "        active_color = mcolors.to_hex(colormap(1.0))\n",
    "        inactive_color = mcolors.to_hex(colormap(0.0))\n",
    "        active_patch = mpatches.Patch(color=active_color, label='Active ligands', edgecolor='black')\n",
    "        inactive_patch = mpatches.Patch(color=inactive_color, label='Inactive ligands', edgecolor='black')\n",
    "        plt.legend(handles=[active_patch, inactive_patch], fontsize=15, loc='upper right', edgecolor='black')\n",
    " \n",
    "    \n",
    "    # Draw the threshold line\n",
    "    plt.axvline(x=hs.thresholds[0].cut_value, color='black', linestyle='--')\n",
    "    # Draw y_cut line\n",
    "    plt.axhline(y=hs.y_cut, color='r', linestyle='--')\n",
    "\n",
    "    # Axis setup\n",
    "    plt.xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}',fontsize=25)\n",
    "    plt.ylabel(output_label,fontsize=25)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.locator_params(axis='x', nbins=5)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "\n",
    "    plt.title(f'{hs.thresholds[0].feature_name} Threshold', fontsize = 25)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the accuracy, precision, and recall of the hotspot\n",
    "    hs.get_external_accuracy(vs_combined_df, verbose=True)\n",
    "\n",
    "def plot_validation_double_threshold(hs:Hotspot, response_data:pd.DataFrame, vs_parameters:pd.DataFrame, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = 'Yield (%)', hide_og=False):\n",
    "    \"\"\"\n",
    "    Plot a validation set on a double threshold\n",
    "\n",
    "    :hs: The hotspot object to plot\n",
    "    :response_data: The experimental output data for the validation set\n",
    "    :vs_parameters: The parameter data for the validation set\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot if also plotting the original data\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default 'Yield (%)'\n",
    "    :hide_og: True (default) if you want to hide the original data points\n",
    "    \"\"\"\n",
    "\n",
    "    x_col,y_col = hs.thresholds[0].index, hs.thresholds[1].index\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # This section auto-scales the plot\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, y_col]))\n",
    "    y_max = float(max(hs.data_df.loc[:, y_col]))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    \n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "    \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "        vs_mapping_cl = response_data.iloc[:, 0]\n",
    "        vmin, vmax = min(hs.data_df.loc[:, 'response']), max(hs.data_df.loc[:, 'response'])\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "        vs_mapping_cl = [1 if i >= hs.y_cut else 0 for i in response_data.iloc[:, 0]]\n",
    "        vmin, vmax = 0, 1\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "        vmin, vmax = min(hs.data_df.loc[:, 'response']), max(hs.data_df.loc[:, 'response'])\n",
    "\n",
    "    # This is where you choose which descriptors to plot\n",
    "    if not hide_og:\n",
    "        x = hs.data_df.loc[points_to_plot,x_col]\n",
    "        y = hs.data_df.loc[points_to_plot,y_col]\n",
    "        plt.scatter(x, y, c=mapping_cl,cmap=gradient_color, edgecolor='black', s=100, vmin=vmin, vmax=vmax)  \n",
    "\n",
    "    # Plot the validation data set on top of the hotspot\n",
    "    vs_x = vs_parameters.loc[response_data.index, x_col]\n",
    "    vs_y = vs_parameters.loc[response_data.index, y_col]\n",
    "    \n",
    "    colormap = plt.get_cmap(gradient_color)\n",
    "    plt.scatter(vs_x, vs_y, c=vs_mapping_cl, cmap=gradient_color, edgecolor='black', s=100, marker='s', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Draw threshold lines\n",
    "    plt.axhline(y=hs.thresholds[1].cut_value, color='black', linestyle='--')\n",
    "    plt.axvline(x=hs.thresholds[0].cut_value, color='black', linestyle='--')\n",
    "    \n",
    "    # Set the gradient bar on the side\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[1], shrink=1)\n",
    "        cbar.set_label(output_label, rotation=90, size=18)\n",
    "        # cbar.set_ticklabels([0,20,40,60,80,100], size=18)\n",
    "    else:\n",
    "    # Display a legend\n",
    "        colormap = plt.get_cmap(gradient_color)\n",
    "        active_color = mcolors.to_hex(colormap(1.0))\n",
    "        inactive_color = mcolors.to_hex(colormap(0.0))\n",
    "        active_patch = mpatches.Patch(color=active_color, label='Active ligands', edgecolor='black')\n",
    "        inactive_patch = mpatches.Patch(color=inactive_color, label='Inactive ligands', edgecolor='black')\n",
    "        plt.legend(handles=[active_patch, inactive_patch], fontsize=15, loc='upper right', edgecolor='black')        \n",
    "\n",
    "    # Axis setup\n",
    "    plt.xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}', fontsize = 15)\n",
    "    plt.ylabel(f'{hs.thresholds[1].feature_label} {hs.thresholds[1].feature_name}', fontsize = 15)\n",
    "    plt.xticks(fontsize = 18)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.yticks(fontsize = 18)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.locator_params(axis = 'y', nbins = 4)\n",
    "\n",
    "    # Title the plot\n",
    "    plt.title(f'{hs.thresholds[0].feature_name} x {hs.thresholds[1].feature_name} Validation', fontsize = 20, y=1.05)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the accuracy, precision, and recall of the hotspot\n",
    "    hs.get_external_accuracy(vs_combined_df, verbose=True)\n",
    "\n",
    "def plot_validation_triple_threshold(hs:Hotspot, response_data:pd.DataFrame, vs_parameters:pd.DataFrame, subset:str = 'all', coloring:str = 'scaled', gradient_color:str = 'Oranges', output_label:str = 'Yield (%)', hide_og=False):\n",
    "    \"\"\"\n",
    "    Plot a validation set on a triple threshold\n",
    "\n",
    "    :hs: The hotspot object to plot\n",
    "    :response_data: The experimental output data for the validation set\n",
    "    :vs_parameters: The parameter data for the validation set\n",
    "    :subset: 'all', 'train', or 'test'; indicates which subset to show on the plot if also plotting the original data\n",
    "    :coloring: 'scaled' or 'binary'; indicates if points should be colored based on actual output values or by output category\n",
    "    :gradient_color: the color scheme applied to the heatmap, default 'Oranges'\n",
    "    :output_label: default 'Yield (%)'\n",
    "    :hide_og: True (default) if you want to hide the original data points\n",
    "    \"\"\"\n",
    "\n",
    "    x_col,y_col,z_col = hs.thresholds[0].index, hs.thresholds[1].index, hs.thresholds[2].index\n",
    "\n",
    "    hotspot_evaluations = hs.expand(vs_parameters_df)\n",
    "    \n",
    "    # Auto-scale the plot to your data\n",
    "    x_min = float(min(hs.data_df.loc[:, x_col]))\n",
    "    x_max = float(max(hs.data_df.loc[:, x_col]))\n",
    "    y_min = float(min(hs.data_df.loc[:, y_col]))\n",
    "    y_max = float(max(hs.data_df.loc[:, y_col]))\n",
    "    z_min = float(min(hs.data_df.loc[:, z_col]))\n",
    "    z_max = float(max(hs.data_df.loc[:, z_col]))\n",
    "\n",
    "    dx = abs(x_min - x_max)\n",
    "    dy = abs(y_min - y_max)\n",
    "    dz = abs(z_min - z_max)\n",
    "\n",
    "    x_min = x_min - abs(dx * 0.05)\n",
    "    x_max = x_max + abs(dx * 0.05)\n",
    "    y_min = y_min - abs(dy * 0.05)\n",
    "    y_max = y_max + abs(dy * 0.05)\n",
    "    z_min = z_min - abs(dz * 0.05)\n",
    "    z_max = z_max + abs(dz * 0.05)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "    # Set which points to plot based on the subset parameter\n",
    "    if(subset == 'all'):\n",
    "        points_to_plot = hs.data_df.index\n",
    "    elif(subset == 'train'):\n",
    "        points_to_plot = hs.training_set\n",
    "    elif(subset == 'test'):\n",
    "        points_to_plot = hs.test_set\n",
    "    else:\n",
    "        points_to_plot = []\n",
    "        \n",
    "    # Change how the points are colored, controlled by the coloring parameter\n",
    "    if(coloring=='scaled'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "        vs_mapping_cl = response_data.iloc[:, 0]\n",
    "    elif(coloring=='binary'):\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'y_class']\n",
    "        vs_mapping_cl = [1 if i >= hs.y_cut else 0 for i in response_data.iloc[:, 0]]\n",
    "    else:\n",
    "        mapping_cl = hs.data_df.loc[points_to_plot, 'response']\n",
    "        vs_mapping_cl = response_data.iloc[:, 0]\n",
    "\n",
    "    # Actually plot the data if not hiding the original data\n",
    "    if(not hide_og):\n",
    "        x = hs.data_df.loc[points_to_plot,x_col]\n",
    "        y = hs.data_df.loc[points_to_plot,y_col]\n",
    "        z = hs.data_df.loc[points_to_plot,z_col]\n",
    "        ax.scatter(x, y, z, c=mapping_cl, cmap=gradient_color, alpha=0.95, marker=\"o\", s=50, edgecolors='k') \n",
    "\n",
    "    # Plot the extra data set on top of the hotspot\n",
    "    vs_x = vs_parameters.loc[response_data.index, x_col]\n",
    "    vs_y = vs_parameters.loc[response_data.index, y_col]\n",
    "    vs_z = vs_parameters.loc[response_data.index, z_col]\n",
    "    ax.scatter(vs_x, vs_y, vs_z, c=vs_mapping_cl, cmap=gradient_color, edgecolor='black', s=100, marker='s', vmin=0, vmax=1, alpha = 0.95)\n",
    "        \n",
    "    # Plot the z-axis threshold\n",
    "    temp_x = np.linspace(x_min, x_max, num=10)\n",
    "    temp_y = np.linspace(y_min, y_max, num=10)\n",
    "    temp_x, temp_y = np.meshgrid(temp_x, temp_y)\n",
    "    temp_z = hs.thresholds[2].cut_value + 0 * temp_x + 0 * temp_y\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray')\n",
    "    \n",
    "    # Plot the x-axis threshold\n",
    "    temp_y = np.linspace(y_min, y_max, num=10)\n",
    "    temp_z = np.linspace(z_min, z_max, num=10)\n",
    "    temp_z, temp_y = np.meshgrid(temp_z, temp_y)\n",
    "    temp_x = hs.thresholds[0].cut_value + 0 * temp_z + 0 * temp_y\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray') \n",
    "    \n",
    "    # Plot the y-axis threshold\n",
    "    temp_x = np.linspace(x_min, x_max, num = 10)\n",
    "    temp_z = np.linspace(z_min, z_max, num = 10)\n",
    "    temp_x, temp_z = np.meshgrid(temp_x, temp_z)\n",
    "    temp_y = hs.thresholds[1].cut_value + 0 * temp_x + 0 * temp_z\n",
    "    ax.plot_surface(temp_x, temp_y, temp_z, alpha=0.15, color='gray')\n",
    "\n",
    "    # Draw a line from the point to the base of the plot\n",
    "    for i in response_data.index.to_list():\n",
    "        x_point = vs_parameters.loc[i, x_col]\n",
    "        y_point = vs_parameters.loc[i, y_col]\n",
    "        z_point = vs_parameters.loc[i, z_col]\n",
    "        if hotspot_evaluations.loc[i].all() == True:\n",
    "            color = 'black'\n",
    "        else:\n",
    "            color = 'black'\n",
    "\n",
    "        if hotspot_evaluations.loc[i].all() == True:\n",
    "            linewidth = 2\n",
    "            alpha = 0.8\n",
    "        else:\n",
    "            linewidth = 1\n",
    "            alpha = 0.3\n",
    "\n",
    "        ax.plot([x_point, x_point], [y_point, y_point], [z_point, z_min], color=color, linewidth=linewidth, alpha=alpha)\n",
    "\n",
    "    \n",
    "    plt.xticks(fontsize = 10) \n",
    "    plt.yticks(fontsize = 10)\n",
    "\n",
    "    # Set axes labels\n",
    "    ax.set_xlabel(f'{hs.thresholds[0].feature_label} {hs.thresholds[0].feature_name}',fontsize=15)\n",
    "    ax.set_ylabel(f'{hs.thresholds[1].feature_label} {hs.thresholds[1].feature_name}',fontsize=15)\n",
    "    ax.set_zlabel(f'{hs.thresholds[2].feature_label} {hs.thresholds[2].feature_name}',fontsize=15)\n",
    "\n",
    "    plt.locator_params(axis='y', nbins=8)\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_zlim(z_min, z_max)\n",
    "\n",
    "   # Set the gradient bar on the side\n",
    "    if(coloring == 'scaled'):\n",
    "        cbar = plt.colorbar(plt.gca().collections[0], shrink=0.5)\n",
    "        cbar.set_label(output_label, rotation=90, size=15)\n",
    "        cbar.set_ticklabels([0,20,40,60,80,100], size=15)\n",
    "\n",
    "    # Set initial plot orientation\n",
    "    ax.view_init(elev=20, azim=210)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the accuracy, precision, and recall of the hotspot\n",
    "    hs.get_external_accuracy(vs_combined_df, verbose=True)\n",
    "\n",
    "plot_validation(hs, vs_response_df, vs_parameters_df, subset='all', coloring='binary', output_label='Yield (%)', hide_og=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab15719",
   "metadata": {},
   "source": [
    "## Virtual Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hotspot to screen against\n",
    "hotspot_index = 0\n",
    "\n",
    "# Set to True if you want to write the virtual screen results to an Excel file\n",
    "write_to_excel = True\n",
    "output_name = 'virtual_screen_output.xlsx'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hs = best_hotspots[hotspot_index]\n",
    "\n",
    "# Trim down to the parameter values relevant to this hotspot and add binary evaluations from each ligand\n",
    "# True in an xID column indicates that the ligand is predicted to be active by that threshold\n",
    "virtual_screen_report_df = vs_parameters_df.loc[:, hs.threshold_indexes]\n",
    "virtual_screen_report_df.columns = [f'{parameter}_{vs_x_labelname_dict[parameter]}' for parameter in virtual_screen_report_df.columns]\n",
    "\n",
    "threshold_evaluations = hs.expand(vs_parameters_df)\n",
    "virtual_screen_report_df = pd.concat([virtual_screen_report_df, threshold_evaluations], axis=1)\n",
    "\n",
    "# Create a column for the final hotspot evaluation if there is more than a single threshold\n",
    "if len(hs.thresholds) > 1:\n",
    "    for ligand in virtual_screen_report_df.index:\n",
    "        evaluation = all([virtual_screen_report_df.loc[ligand, threshold] for threshold in hs.threshold_indexes])\n",
    "        virtual_screen_report_df.loc[ligand, 'Full Hotspot Evaluation'] = evaluation\n",
    "\n",
    "display(virtual_screen_report_df)\n",
    "\n",
    "if write_to_excel:\n",
    "    virtual_screen_report_df.to_excel(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57721b",
   "metadata": {},
   "source": [
    "# Show Hotspots on PCA/UMAP Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9b0d9",
   "metadata": {},
   "source": [
    "### Read in full descriptor library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the excel sheet has a row of xID labels then a row of full parameter names\n",
    "# Import the parameters for the virtual screen\n",
    "dr_parameters_file = \"kraken descriptors\" \n",
    "dr_parameters_sheet = \"DFT_data\" \n",
    "dr_number_parameters = 190\n",
    "dr_parameters_start_col = 1   # 0-indexed\n",
    "dr_parameters_num_samples = 1560 \n",
    "dr_parameters_y_label_col = 0  # 0-indexed\n",
    "dr_parameters_header_rows = 0\n",
    "\n",
    "\n",
    "# Actually start reading stuff into the parameter dataframe\n",
    "dr_parameters_df = pd.read_excel(\"./InputData/\" + dr_parameters_file + \".xlsx\",\n",
    "                              dr_parameters_sheet,\n",
    "                              header = dr_parameters_header_rows,\n",
    "                              index_col = dr_parameters_y_label_col,\n",
    "                              nrows = dr_parameters_num_samples + 1,\n",
    "                              usecols = list(range(0, (dr_number_parameters + dr_parameters_start_col)))\n",
    "                              )\n",
    "\n",
    "dr_parameters_df.drop(dr_parameters_df.index[0], inplace=True) # Remove the full parameter name row\n",
    "dr_parameters_df.index = dr_parameters_df.index.astype(int) # This converts the index (molecule/reaction number) from strings to ints\n",
    "\n",
    "# Convert all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "dr_parameters_df = dr_parameters_df.dropna()\n",
    "for column in dr_parameters_df.columns:\n",
    "    dr_parameters_df[column] = pd.to_numeric(dr_parameters_df[column], errors='coerce')\n",
    "\n",
    "# Create a dictionary to convert x# labels to full parameter names\n",
    "dr_x_names = list(dr_parameters_df.iloc[0, dr_parameters_start_col - 1 : dr_number_parameters + dr_parameters_start_col - 1])\n",
    "dr_x_labels = list(dr_parameters_df.columns)[dr_parameters_start_col - 1 : dr_number_parameters + dr_parameters_start_col - 1]\n",
    "dr_x_labelname_dict = dict(zip(dr_x_labels, dr_x_names))\n",
    "\n",
    "display(dr_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf7277",
   "metadata": {},
   "source": [
    "### Plot the hotspot on reduced dimension space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which dimensionality reduction type to plot (PCA or UMAP)\n",
    "DR_sheet = 'UMAP'\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "DR = pd.read_excel('./InputData/kraken descriptors.xlsx', DR_sheet, index_col=0, header=0)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hotspot_validation_list = best_hotspots[0].expand(dr_parameters_df)\n",
    "print(hotspot_validation_list)\n",
    "\n",
    "# Make a list of indicies in in_hotspot_list where both columns are true\n",
    "in_hotspot_list = hotspot_validation_list[hotspot_validation_list.all(axis=1)]\n",
    "in_hotspot_list = in_hotspot_list.index.to_list()\n",
    "\n",
    "# Make a list of indicies in in_hotspot_list where both columns are not true\n",
    "not_in_hotspot_list = hotspot_validation_list[~hotspot_validation_list.all(axis=1)]\n",
    "not_in_hotspot_list = not_in_hotspot_list.index.to_list()\n",
    "not_in_hotspot_list = [x for x in not_in_hotspot_list if x in DR.index]\n",
    "\n",
    "x_row = 0\n",
    "y_row = 1\n",
    "\n",
    "### This section auto-scales the plot\n",
    "x_min = min(DR.iloc[:,x_row])\n",
    "x_max = max(DR.iloc[:,x_row])\n",
    "y_min = min(DR.iloc[:,y_row])\n",
    "y_max = max(DR.iloc[:,y_row])\n",
    "\n",
    "dx = abs(x_min-x_max)\n",
    "dy = abs(y_min-y_max)\n",
    "\n",
    "x_min = x_min - abs(dx*0.05)\n",
    "x_max = x_max + abs(dx*0.05)\n",
    "y_min = y_min - abs(dy*0.05)\n",
    "y_max = y_max + abs(dy*0.05)\n",
    "\n",
    "plt.xlabel(f'{DR_sheet} 1',fontsize=18)\n",
    "plt.ylabel(f'{DR_sheet} 2',fontsize=18)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "if(DR_sheet == 'PCA'):\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.locator_params(axis='x', nbins=5)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "elif(DR_sheet == 'UMAP'):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Make a list of ones the same length as in_hotspot_list\n",
    "max_color = [1] * len(in_hotspot_list)\n",
    "\n",
    "# Plot the ligands not in the hotspot\n",
    "plt.scatter(DR.loc[not_in_hotspot_list, DR.columns[0]], DR.loc[not_in_hotspot_list, DR.columns[1]],c='white', edgecolor='black', s=100, alpha=0.7)\n",
    "# Plot the ligands in the hotspot\n",
    "plt.scatter(DR.loc[in_hotspot_list, DR.columns[0]], DR.loc[in_hotspot_list, DR.columns[1]], cmap='Oranges', c=max_color, edgecolor='black', s=100, alpha=0.7)  \n",
    "\n",
    "# Include a legend for the colors\n",
    "plt.clim(vmin=0, vmax=1)\n",
    "plt.legend(['Not in Hotspot', 'In Hotspot'], fontsize=18)\n",
    "\n",
    "\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multithreshold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.617px",
    "left": "337.667px",
    "right": "20px",
    "top": "258px",
    "width": "506.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
