{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863b013a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af081774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:25.616028Z",
     "start_time": "2023-09-28T18:07:23.704214Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import hotspot_utils\n",
    "from hotspot_classes import Hotspot\n",
    "\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "NUM_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cefa64",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38059b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:29.051824Z",
     "start_time": "2023-09-28T18:07:25.905944Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell reads in parameters and response data from Excel files and combines them into a single dataframe\n",
    "# Check cell outputs to make sure everything looks good\n",
    "\n",
    "parameters_file = \"Multi-Threshold Analysis Data\" # Excel file to pull parameters from\n",
    "parameters_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull parameters from\n",
    "parameters_start_col = 3   # 0-indexed column number where the parameters start\n",
    "parameters_num_parameters = 190 # Number of parameters in the parameters file\n",
    "parameters_num_responses = 450 # Number of responses/ligands in the parameters file\n",
    "parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "response_file = \"Multi-Threshold Analysis Data\" # Excel file to pull responses from\n",
    "response_sheet = \"Suzuki Yields and Parameters\" # Sheet in the Excel file to pull responses from\n",
    "response_num_samples = 450 # Number of samples/reactions in the response file\n",
    "response_col = 1 # 0-indexed column number for the responses\n",
    "response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "response_header_rows = 1 # Number of rows to skip when reading the responses\n",
    "\n",
    "# If the parameters and outputs are on different sheets, you can use the following code to read them in separately\n",
    "\n",
    "# parameters_file = \"kraken descriptors\" # Excel file to pull parameters from\n",
    "# parameters_sheet = \"DFT_data\" # Sheet in the Excel file to pull parameters from\n",
    "# parameters_start_col = 1   # 0-indexed column number where the parameters start\n",
    "# parameters_num_parameters = 190 # Number of parameters in the parameters file\n",
    "# parameters_num_responses = 1560 # Number of responses/ligands in the parameters file\n",
    "# parameters_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# parameters_header_rows = 0 # Number of rows to skip when reading the parameters\n",
    "\n",
    "# response_file = \"Multi-Threshold Analysis Data\" # Excel file to pull responses from\n",
    "# response_sheet = \"Reactions VI-IX\" # Sheet in the Excel file to pull responses from\n",
    "# response_num_samples = 100 # Number of samples/reactions in the response file\n",
    "# response_col = 2 # 0-indexed column number for the responses\n",
    "# response_y_label_col = 0  # 0-indexed column number where the ligand labels are\n",
    "# response_header_rows = 0 # Number of rows to skip when reading the responses\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# EDIT ABOVE THIS LINE\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Actually start reading stuff into dataframes\n",
    "parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_responses + 1,\n",
    "                              usecols = list(range(0, (parameters_num_parameters + parameters_start_col)))\n",
    "                              )\n",
    "response_df = pd.read_excel(\"./InputData/\" + response_file + \".xlsx\",\n",
    "                            response_sheet,\n",
    "                            header = response_header_rows,\n",
    "                            index_col = response_y_label_col,\n",
    "                            nrows = response_num_samples,\n",
    "                            usecols = list(range(0, response_col + 1))\n",
    "                            )\n",
    "\n",
    "\n",
    "# Drop any columns before parameters_start_col that are not the index column\n",
    "parameters_columns_to_keep = [col for col in range(0, len(parameters_df.columns)) if col >= parameters_start_col-1]\n",
    "parameters_df = parameters_df.iloc[:,parameters_columns_to_keep]\n",
    "\n",
    "# Combine the two dataframes into the master dataframe\n",
    "response_df.drop(response_df.columns[0:response_col-1], axis = 'columns', inplace = True)\n",
    "response_df['y_class'] = 0 # This should create the \"y_class\" column that will ultimately be used for classification labels\n",
    "data_df = response_df.merge(parameters_df, left_index = True, right_index = True)\n",
    "data_df.columns.values[0] = 'response' # Converts the output column name from whatever it is on the spreadsheet\n",
    "data_df.dropna(inplace = True) # This covers the entire masking section and trims the dataframe down to only the rows relevant to this dataset\n",
    "\n",
    "# This converts all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "for column in data_df.columns:\n",
    "    data_df[column] = pd.to_numeric(data_df[column], errors='coerce')\n",
    "data_df.dropna(inplace = True)\n",
    "\n",
    "# Creates a dictionary to convert x# labels to full parameter names\n",
    "x_names = list(parameters_df.iloc[0, :parameters_num_parameters])\n",
    "x_labels = list(parameters_df.columns)[:parameters_num_parameters]\n",
    "x_labelname_dict = dict(zip(x_labels, x_names))\n",
    "\n",
    "# Print out some information about the dataframe to confirm it was read in correctly\n",
    "print(\"Parameter file shape: {}\".format(parameters_df.shape))\n",
    "print(\"Final parameter quantity: {}\".format(len(x_labels)))\n",
    "print(\"Final experiment quantity: {}\".format(data_df.shape[0]))\n",
    "print(\"First parameter cell: {}\".format(data_df[x_labels[0]].iloc[0]))\n",
    "print(\"Last parameter cell:  {}\".format(data_df[x_labels[-1]].iloc[-1]))\n",
    "print(\"First response: {}\".format(data_df.iloc[0,0]))\n",
    "print(\"Last response:  {}\".format(data_df.iloc[-1,0]))\n",
    "print(\"First reaction label: {}\".format(data_df.index[0]))\n",
    "print(\"Last reaction label:  {}\".format(data_df.index[-1]))\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb07018",
   "metadata": {},
   "source": [
    "# Training/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cb079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:42.192285Z",
     "start_time": "2023-09-28T18:07:42.102266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Divide the data into training and test sets\n",
    "# split options are 'random', 'ks' (kennard-stone), 'y_equidist' (equidistant in y), 'define' (manual selection) and 'none'\n",
    "split = \"none\"\n",
    "test_ratio = 0.3 \n",
    "\n",
    "training_set, test_set = hotspot_utils.train_test_splits(data_df, split, test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b3fc6",
   "metadata": {},
   "source": [
    "# Run the Combined Threshold Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bd2e9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Automatic Threshold Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe3f47",
   "metadata": {},
   "source": [
    "Edit and run the first cell to set the parameters of the threshold analysis, then run the second cell without changing anything (unless you have a good reason to) to start the calculations.\n",
    "\n",
    "This section automatically identifies the best hotspots/multi-thresholds based on the parameters set in the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7cb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:07:29.320787Z",
     "start_time": "2023-09-28T18:07:29.306785Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cutoff in your output for what counts as an active ligand\n",
    "y_cut = 10\n",
    "\n",
    "# Set to True if you want points below the y-cut to be considered active\n",
    "low_is_good = False\n",
    "\n",
    "# How heavily to value active ligands (1) over inactive ligands (0)\n",
    "class_weight = {1:10, 0:1} \n",
    "\n",
    "# How the prune_hotspots and find_best_hotspots evaluates which are the best\n",
    "# Can be set to 'accuracy', 'weighted_accuracy', 'f1', and 'weighted_f1'\n",
    "evaluation_method = 'weighted_accuracy'\n",
    "\n",
    "# How many threshold dimensions do you want?\n",
    "n_thresholds = 2\n",
    "\n",
    "# What percentage of thresholds are analyzed in each subsequent step\n",
    "percentage = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up y_class, the binary list of which y values are above y_cut\n",
    "if(low_is_good):\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] < y_cut)\n",
    "else:\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] > y_cut)\n",
    "\n",
    "# Find the best thresholds within the full X and y space and make single threshold hotspot objects from them\n",
    "all_thresholds = hotspot_utils.threshold_generation(data_df, class_weight, evaluation_method, x_labelname_dict)\n",
    "best_hotspots = []\n",
    "for thresh in all_thresholds:\n",
    "    temp_hs = Hotspot(data_df, [thresh], y_cut, training_set, test_set, evaluation_method, class_weight)\n",
    "    best_hotspots.append(temp_hs)\n",
    "\n",
    "# Cut down to the best {percentage} hotspots\n",
    "best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "\n",
    "# Add more thresholds, pruning after each step for resource management\n",
    "for i in range(n_thresholds - 1):\n",
    "    with Pool(processes=int(NUM_CORES*.7)) as p:\n",
    "        new_hotspots = p.starmap(hotspot_utils.hs_next_thresholds_fast, zip(best_hotspots, repeat(all_thresholds)))\n",
    "    new_hotspots = [item for sublist in new_hotspots for item in sublist] \n",
    "    \n",
    "    best_hotspots = hotspot_utils.prune_hotspots(new_hotspots, percentage, evaluation_method)\n",
    "\n",
    "best_hotspots.sort(key = lambda x: x.accuracy_dict[evaluation_method], reverse = True)\n",
    "\n",
    "# print the top 5 hotspots\n",
    "for i, hs in enumerate(best_hotspots[:5]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50faa826",
   "metadata": {},
   "source": [
    "## Manual Threshold Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a86187",
   "metadata": {},
   "source": [
    "Edit and run the first cell to set the parameters of the threshold analysis, then run the second cell without changing anything (unless you have a good reason to) to start the calculations.\n",
    "\n",
    "This section allows you to manually select which feature(s) or range of features are used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b52da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:11:27.829533Z",
     "start_time": "2023-09-28T18:11:27.817523Z"
    }
   },
   "outputs": [],
   "source": [
    "# What features do you want in your hotspot?\n",
    "# For ranges, use data_df.columns[x:y].to_list() to get a list of feature xIDs\n",
    "# For specific features, use ['xID1', 'xID2', ...]\n",
    "\n",
    "# manual_features = [['x1'], ['x87']]\n",
    "# manual_features = [['x87']]\n",
    "manual_features = [['x1'], ['x87'], data_df.columns[3:].to_list()]\n",
    "\n",
    "# Cutoff for what counts as a hit\n",
    "y_cut = 10\n",
    "\n",
    "# How heavily to value hits (1) over misses (0)\n",
    "class_weight = {1:10, 0:1} \n",
    "\n",
    "# What percentage of hotspots to take through to each subsequent step\n",
    "# Only relevant if using ranges instead of specific parameters\n",
    "percentage = 100\n",
    "\n",
    "# How the prune_hotspots and find_best_hotspots evaluates which are the best\n",
    "# Can be set to 'accuracy', 'weighted_accuracy', 'f1', and 'weighted_f1'\n",
    "evaluation_method = 'weighted_accuracy'\n",
    "\n",
    "# Set to True if you want a hotspot of low output results (cold spot?)\n",
    "low_is_good = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110d9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:11:28.932105Z",
     "start_time": "2023-09-28T18:11:28.819069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up y_class, the binary list of which y values are above y_cut\n",
    "if(low_is_good):\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] < y_cut)\n",
    "else:\n",
    "    for i in data_df.index:\n",
    "        data_df.loc[i, 'y_class'] = int(data_df.loc[i, 'response'] > y_cut)\n",
    "\n",
    "# Find the best thresholds within the full X and y space and make single threshold hotspot objects from them\n",
    "all_thresholds = hotspot_utils.threshold_generation(data_df, class_weight, evaluation_method, x_labelname_dict, manual_features[0])\n",
    "best_hotspots = []\n",
    "for thresh in all_thresholds:\n",
    "    temp_hs = Hotspot(data_df, [thresh], y_cut, training_set, test_set, evaluation_method, class_weight)\n",
    "    best_hotspots.append(temp_hs)\n",
    "\n",
    "# Cut down to the best {percentage} hotspots\n",
    "best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "\n",
    "# Add more thresholds, pruning after each step for resource management\n",
    "for i in range(len(manual_features) - 1):\n",
    "    new_hotspots = []\n",
    "    for hs in best_hotspots:\n",
    "        temp_hotspots = hotspot_utils.hs_next_thresholds(hs, data_df, class_weight, x_labelname_dict, manual_features[i+1])\n",
    "        new_hotspots.extend(temp_hotspots)\n",
    "    best_hotspots = new_hotspots\n",
    "    del (new_hotspots)\n",
    "    best_hotspots = hotspot_utils.prune_hotspots(best_hotspots, percentage, evaluation_method)\n",
    "    \n",
    "best_hotspots.sort(key = lambda x: x.accuracy_dict[evaluation_method], reverse = True)\n",
    "\n",
    "# print the top 5 hotspots\n",
    "for i, hs in enumerate(best_hotspots[:5]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bfbd7",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f1a2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Print Longer List of Hotspots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28e8d2",
   "metadata": {},
   "source": [
    "This cell prints the text output for a longer list of hotspots if you want to see more than were given in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178fdb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T19:04:05.022913Z",
     "start_time": "2023-01-30T19:04:05.014923Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How many hotspots do you want listed?\n",
    "n = 50\n",
    "\n",
    "for i, hs in enumerate(best_hotspots[:n]):\n",
    "    print(f'Hotspot Index: {i}')\n",
    "    print(hs)\n",
    "    hs.print_stats()\n",
    "    print('\\n**********************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff653",
   "metadata": {},
   "source": [
    "## Display Individual Hotspot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fbe91",
   "metadata": {},
   "source": [
    "For more further control over plot style, changes can be made to functions in the hotsput_utils.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef61685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the hotspot you want to plot based on its index\n",
    "hotspot_index = 0\n",
    "\n",
    "print(best_hotspots[hotspot_index])\n",
    "\n",
    "# subset can be 'all', 'training', or 'test'\n",
    "# You can change the coloring to either 'scaled' or 'binary'\n",
    "# output_label is whatever you call your output (Only relevant when using 'scaled' coloring or single threshold)\n",
    "hotspot_utils.plot_hotspot(best_hotspots[hotspot_index], subset='all', coloring='scaled', output_label='Yield (%)', gradient_color='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc47692",
   "metadata": {},
   "source": [
    "# Virtual Screening / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f864f6",
   "metadata": {},
   "source": [
    "## Import Virtual Screening / Validation Parameter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9264a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the parameters for the previously unseen molecules, required for both virtual screening and validation\n",
    "# This assumes the excel sheet has a row of xID labels then a row of full parameter names\n",
    "parameters_file = \"kraken descriptors\" \n",
    "parameters_sheet = \"DFT_data\" \n",
    "parameters_num_parameters = 190\n",
    "parameters_start_col = 1   # 0-indexed\n",
    "parameters_num_samples = 1560 \n",
    "parameters_y_label_col = 0  # 0-indexed\n",
    "parameters_header_rows = 0\n",
    "\n",
    "\n",
    "# Actually start reading stuff into the parameter dataframe\n",
    "vs_parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_samples + 1,\n",
    "                              usecols = list(range(0, (parameters_num_parameters + parameters_start_col)))\n",
    "                              )\n",
    "\n",
    "# Create a dictionary to convert x# labels to full parameter names\n",
    "vs_x_names = list(vs_parameters_df.iloc[0, parameters_start_col - 1 : parameters_num_parameters + parameters_start_col - 1])\n",
    "vs_x_labels = list(vs_parameters_df.columns)[parameters_start_col - 1 : parameters_num_parameters + parameters_start_col - 1]\n",
    "vs_x_labelname_dict = dict(zip(vs_x_labels, vs_x_names))\n",
    "\n",
    "vs_parameters_df.drop(vs_parameters_df.index[0], inplace=True) # Remove the full parameter name row\n",
    "vs_parameters_df.index = vs_parameters_df.index.astype(int) # This converts the index (molecule/reaction number) from strings to ints\n",
    "\n",
    "# Convert all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "for column in vs_parameters_df.columns:\n",
    "    vs_parameters_df[column] = pd.to_numeric(vs_parameters_df[column], errors='coerce')\n",
    "\n",
    "display(vs_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a18719",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation results from the excel sheet\n",
    "# The final result should be a dataframe with indicies corresponding to the vs_parameters_df from above,\n",
    "# a column of experimental outputs, and all the relevant parameters\n",
    "\n",
    "validation_file = \"Multi-Threshold Analysis Data\"\n",
    "validation_sheet = \"Reaction II Validation (2)\"\n",
    "validation_experimental_col = 2\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "vs_response_df = pd.read_excel('./InputData/' + validation_file + '.xlsx',\n",
    "                              sheet_name=validation_sheet,\n",
    "                              index_col=0,\n",
    "                              )\n",
    "\n",
    "# Drop all columns except the experimental output\n",
    "vs_response_df = vs_response_df.iloc[:, [validation_experimental_col-1]]\n",
    "vs_response_df.columns = ['response']\n",
    "\n",
    "for column in vs_response_df.columns:\n",
    "    vs_response_df[column] = pd.to_numeric(vs_response_df[column], errors='coerce')\n",
    "vs_response_df.dropna(inplace = True)\n",
    "\n",
    "vs_combined_df = pd.concat([vs_response_df, vs_parameters_df], axis=1, join='inner')\n",
    "\n",
    "display(vs_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d520c9",
   "metadata": {},
   "source": [
    "### Print/Export Validation Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hotspot to validate\n",
    "hotspot_index = 0\n",
    "\n",
    "# Set to True if you want to write the validation results to an Excel file\n",
    "write_to_excel = False\n",
    "output_name = 'validation_output.xlsx'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hs = best_hotspots[hotspot_index]\n",
    "\n",
    "# Begin the output dataframe with the experimental results and the y_class column\n",
    "validation_report_df = vs_response_df.copy()\n",
    "validation_report_df['y_class'] = [y > hs.y_cut for y in validation_report_df.iloc[:, 0]]\n",
    "\n",
    "# Add the parameter values and binary evaluations for each ligand to the output dataframe\n",
    "# True in an xID column indicates that the ligand is predicted to be active by that threshold\n",
    "for parameter in hs.threshold_indexes:\n",
    "    validation_report_df[f'{parameter}_{vs_x_labelname_dict[parameter]}'] = vs_parameters_df.loc[validation_report_df.index, parameter]\n",
    "\n",
    "threshold_evaluations = hs.expand(vs_parameters_df.loc[validation_report_df.index])\n",
    "validation_report_df = pd.concat([validation_report_df, threshold_evaluations], axis=1)\n",
    "\n",
    "# Create a column for the final hotspot evaluation if there is more than a single threshold\n",
    "if len(hs.thresholds) > 1:\n",
    "    for ligand in validation_report_df.index:\n",
    "        evaluation = all([validation_report_df.loc[ligand, threshold] for threshold in hs.threshold_indexes])\n",
    "        validation_report_df.loc[ligand, 'Full Hotspot Evaluation'] = evaluation\n",
    "\n",
    "display(validation_report_df)\n",
    "\n",
    "hs.get_external_accuracy(vs_combined_df, verbose=True)\n",
    "\n",
    "if write_to_excel:\n",
    "    validation_report_df.to_excel(output_name)\n",
    "\n",
    "# hide_training can be set to True to only plot the validation data\n",
    "# You can change the coloring to either 'scaled' or 'binary'\n",
    "# output_label is whatever you call your output (Only relevant when using 'scaled' coloring or single threshold)\n",
    "hotspot_utils.plot_hotspot(hs, vs_response_df, vs_parameters_df, hide_training=True, coloring='binary', output_label='Yield (%)', gradient_color='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab15719",
   "metadata": {},
   "source": [
    "## Virtual Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hotspot to screen against\n",
    "hotspot_index = 0\n",
    "\n",
    "# Set to True if you want to write the virtual screen results to an Excel file\n",
    "write_to_excel = True\n",
    "output_name = 'virtual_screen_output.xlsx'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hs = best_hotspots[hotspot_index]\n",
    "\n",
    "# Trim down to the parameter values relevant to this hotspot and add binary evaluations from each ligand\n",
    "# True in an xID column indicates that the ligand is predicted to be active by that threshold\n",
    "virtual_screen_report_df = vs_parameters_df.loc[:, hs.threshold_indexes]\n",
    "virtual_screen_report_df.columns = [f'{parameter}_{vs_x_labelname_dict[parameter]}' for parameter in virtual_screen_report_df.columns]\n",
    "\n",
    "threshold_evaluations = hs.expand(vs_parameters_df)\n",
    "virtual_screen_report_df = pd.concat([virtual_screen_report_df, threshold_evaluations], axis=1)\n",
    "\n",
    "# Create a column for the final hotspot evaluation if there is more than a single threshold\n",
    "if len(hs.thresholds) > 1:\n",
    "    for ligand in virtual_screen_report_df.index:\n",
    "        evaluation = all([virtual_screen_report_df.loc[ligand, threshold] for threshold in hs.threshold_indexes])\n",
    "        virtual_screen_report_df.loc[ligand, 'Full Hotspot Evaluation'] = evaluation\n",
    "\n",
    "if write_to_excel:\n",
    "    virtual_screen_report_df.to_excel(output_name)\n",
    "\n",
    "display(virtual_screen_report_df)\n",
    "\n",
    "print('The plot below is meant only to show the distribution of the virtual screen since experimental data has not been supplied')\n",
    "hotspot_utils.plot_hotspot(hs, vs_parameters=vs_parameters_df, hide_training=False, coloring='binary', output_label='Yield (%)', gradient_color='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57721b",
   "metadata": {},
   "source": [
    "# Show Hotspots on PCA/UMAP Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9b0d9",
   "metadata": {},
   "source": [
    "### Read in full descriptor library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the excel sheet has a row of xID labels then a row of full parameter names\n",
    "# Import the parameters for the virtual screen\n",
    "dr_parameters_file = \"kraken descriptors\" \n",
    "dr_parameters_sheet = \"DFT_data\" \n",
    "dr_number_parameters = 190\n",
    "dr_parameters_start_col = 1   # 0-indexed\n",
    "dr_parameters_num_samples = 1560 \n",
    "dr_parameters_y_label_col = 0  # 0-indexed\n",
    "dr_parameters_header_rows = 0\n",
    "\n",
    "\n",
    "# Actually start reading stuff into the parameter dataframe\n",
    "dr_parameters_df = pd.read_excel(\"./InputData/\" + dr_parameters_file + \".xlsx\",\n",
    "                              dr_parameters_sheet,\n",
    "                              header = dr_parameters_header_rows,\n",
    "                              index_col = dr_parameters_y_label_col,\n",
    "                              nrows = dr_parameters_num_samples + 1,\n",
    "                              usecols = list(range(0, (dr_number_parameters + dr_parameters_start_col)))\n",
    "                              )\n",
    "\n",
    "dr_parameters_df.drop(dr_parameters_df.index[0], inplace=True) # Remove the full parameter name row\n",
    "dr_parameters_df.index = dr_parameters_df.index.astype(int) # This converts the index (molecule/reaction number) from strings to ints\n",
    "\n",
    "# Convert all the data to numeric values since it was reading them in as non-numeric objects for some reason\n",
    "dr_parameters_df = dr_parameters_df.dropna()\n",
    "for column in dr_parameters_df.columns:\n",
    "    dr_parameters_df[column] = pd.to_numeric(dr_parameters_df[column], errors='coerce')\n",
    "\n",
    "# Create a dictionary to convert x# labels to full parameter names\n",
    "dr_x_names = list(dr_parameters_df.iloc[0, dr_parameters_start_col - 1 : dr_number_parameters + dr_parameters_start_col - 1])\n",
    "dr_x_labels = list(dr_parameters_df.columns)[dr_parameters_start_col - 1 : dr_number_parameters + dr_parameters_start_col - 1]\n",
    "dr_x_labelname_dict = dict(zip(dr_x_labels, dr_x_names))\n",
    "\n",
    "display(dr_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf7277",
   "metadata": {},
   "source": [
    "### Plot the hotspot on reduced dimension space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which dimensionality reduction type to plot (PCA or UMAP)\n",
    "DR_sheet = 'UMAP'\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "DR = pd.read_excel('./InputData/kraken descriptors.xlsx', DR_sheet, index_col=0, header=0)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "hotspot_validation_list = best_hotspots[0].expand(dr_parameters_df)\n",
    "print(hotspot_validation_list)\n",
    "\n",
    "# Make a list of indicies in in_hotspot_list where both columns are true\n",
    "in_hotspot_list = hotspot_validation_list[hotspot_validation_list.all(axis=1)]\n",
    "in_hotspot_list = in_hotspot_list.index.to_list()\n",
    "\n",
    "# Make a list of indicies in in_hotspot_list where both columns are not true\n",
    "not_in_hotspot_list = hotspot_validation_list[~hotspot_validation_list.all(axis=1)]\n",
    "not_in_hotspot_list = not_in_hotspot_list.index.to_list()\n",
    "not_in_hotspot_list = [x for x in not_in_hotspot_list if x in DR.index]\n",
    "\n",
    "x_row = 0\n",
    "y_row = 1\n",
    "\n",
    "### This section auto-scales the plot\n",
    "x_min = min(DR.iloc[:,x_row])\n",
    "x_max = max(DR.iloc[:,x_row])\n",
    "y_min = min(DR.iloc[:,y_row])\n",
    "y_max = max(DR.iloc[:,y_row])\n",
    "\n",
    "dx = abs(x_min-x_max)\n",
    "dy = abs(y_min-y_max)\n",
    "\n",
    "x_min = x_min - abs(dx*0.05)\n",
    "x_max = x_max + abs(dx*0.05)\n",
    "y_min = y_min - abs(dy*0.05)\n",
    "y_max = y_max + abs(dy*0.05)\n",
    "\n",
    "plt.xlabel(f'{DR_sheet} 1',fontsize=18)\n",
    "plt.ylabel(f'{DR_sheet} 2',fontsize=18)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "if(DR_sheet == 'PCA'):\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.locator_params(axis='x', nbins=5)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "elif(DR_sheet == 'UMAP'):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Make a list of ones the same length as in_hotspot_list\n",
    "max_color = [1] * len(in_hotspot_list)\n",
    "\n",
    "# Plot the ligands not in the hotspot\n",
    "plt.scatter(DR.loc[not_in_hotspot_list, DR.columns[0]], DR.loc[not_in_hotspot_list, DR.columns[1]],c='white', edgecolor='black', s=100, alpha=0.7)\n",
    "# Plot the ligands in the hotspot\n",
    "plt.scatter(DR.loc[in_hotspot_list, DR.columns[0]], DR.loc[in_hotspot_list, DR.columns[1]], cmap='Oranges', c=max_color, edgecolor='black', s=100, alpha=0.7)  \n",
    "\n",
    "# Include a legend for the colors\n",
    "plt.clim(vmin=0, vmax=1)\n",
    "plt.legend(['Not in Hotspot', 'In Hotspot'], fontsize=18)\n",
    "\n",
    "\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multithreshold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.617px",
    "left": "337.667px",
    "right": "20px",
    "top": "258px",
    "width": "506.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
